\documentclass{article}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{dirtytalk}
\usepackage{pgfplotstable}
\usepackage{pgfplots}
\usepackage{datatool}
\usepackage{siunitx}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{float}
\usepackage[style=ieee]{biblatex}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\usepackage{comment}
\usepackage[normalem]{ulem}
\usepackage[
  left=2.5cm,
  right=2.5cm,
  top=2cm,
  bottom=2cm
]{geometry}
\usepackage{titling}
\usepackage{booktabs}

\setlength{\droptitle}{-1in}
\useunder{\uline}{\ul}{}

\addbibresource{main.bib}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue,
    citecolor=blue,
}

\pgfplotsset{compat=1.18}

\title{Individual Plan Master's Thesis}
\author{Name: Casper Ove Kristiansson\\Email: Casperkr@kth.se}
\date{\today}

\begin{document}

\setlength\parindent{0pt}
\maketitle

\section{Project Information}
\begin{itemize}
  \item \textbf{Preliminary Title:} From Experiment to Insight: A Comparative Study of Storage Approaches for Large-Scale Synchrotron and Neutron Scattering Data on AWS
  \item \textbf{Examiner (KTH):} Prof.\ Mats Nordahl
  \item \textbf{Supervisor (KTH):} Prof.\ Sebastian Dalleiger
  \item \textbf{Industry/External Supervisor:} Dr.\ Ahmet Bahadır Yıldız (Scatterin AB) — \texttt{ahmet@scatterin.com}
  \item \textbf{Keywords:} Synchrotron data; Neutron scattering; Cloud storage; AWS; HDF5; Zarr; Parquet;  DynamoDB;  Scientific workflows Arrow/Feather; ROOT; Compression;
\end{itemize}




\section{Background \& Objective}
\subsection{Scientific / Societal Context}
Modern synchrotron and neutron facilities face issues with data handling where experiments can produce terabytes of data per day, which has overwhelmed traditional storage and analysis methods \cite{wang2018synchrotron}. During the last decade, numerous strategies have emerged to optimize data storage, management, and access for these large-scale scientific datasets. This thesis will investigate and prototype certain cloud-based solutions (particularly on Amazon Web Services) to handle large volumes of experimental data.

\subsection{Interest of Organization (Scatterin AB)}
Scatterin AB currently has a commercial platform that provides materials data analytics. With this platform, the current infrastructure has quite a few drawbacks regarding how it is set up and handles large-scale data sets.

\subsection{High-Level Objective}
This thesis intends to \emph{compare} multiple AWS-oriented storage approaches (HDF5, Zarr, Parquet, Arrow/Feather, ROOT, and DynamoDB) using real-world synchrotron/neutron datasets. The goal is to characterize the performance (latency, throughput, compression efficiency), cost, and ease of integration for partial retrieval or queries, basic remote append/delete operations, as well as key operations in beamline and scattering experiments.


\subsection{Required Background Knowledge}
I am completing an MSc in Computer Science at KTH with coursework in \emph{Data-Intensive Computing, Data Storage Paradigms, Advanced Algorithms}, and significant experience (2,000+ hours) as a Full-Stack Developer at Scatterin AB, building AWS-based platforms for scientific data.






\section{Research Question \& Method}

\subsection{Research Question}
How do six candidate formats HDF5, Zarr, Parquet, Arrow/Feather, ROOT, and DynamoDB, compare in performance, scalability, cost, and compression efficiency when storing large-scale synchrotron and neutron scattering data on AWS, especially for partial retrieval?


\subsection{Hypothesis}
\begin{enumerate}
    \item \textbf{Columnar Advantage (Parquet):} Columnar storage (Parquet) should excel for queries involving partial-column reads, reducing I/O overhead.
    \item \textbf{Chunked Object Storage (Zarr):} Zarr’s chunk-based design may outperform HDF5 for parallel reads/writes in a purely cloud-native (object store) environment.
    \item \textbf{HDF5 Familiarity:} HDF5 may remain favorable for certain multidimensional access patterns or legacy HPC-style workflows.
    \item \textbf{NoSQL (DynamoDB) Trade-offs:} DynamoDB may be beneficial for extremely high concurrency, but less suitable for large-scale partial scans (e.g., retrieving entire columns or slices of data).
    \item \textbf{Zero-Copy Columnar (Arrow/Feather):} Arrow/Feather will outperform Parquet and other formats on large bulk reads due to its memory-mapped, zero-copy design, yielding lower latency and higher throughput.
    \item \textbf{ROOT Multidimensional (ROOT):} ROOT’s tree-based file structure will offer efficient selective access for nested, multidimensional datasets, matching or exceeding HDF5’s performance for complex beamline data slices.

\end{enumerate}

\subsection{Objectives}
\begin{enumerate}
    \item Build prototypes for six storage formats (HDF5, Zarr, Parquet, Arrow/Feather, ROOT, DynamoDB) ingesting $\sim$1 TB of two data types, tabular (1 M×20) and dense (x,y) arrays where each tested with and without \{zstd, LZ4, gzip\}.
    \item Produce performance and compression metrics (latency, throughput, compression ratio, CPU overhead).
    \item Compute month-long TCO scenarios for hot/warm/cold access tiers
    \item Produce a concise decision matrix that highlights trade-offs and recommends when to choose each storage approach.
\end{enumerate}


\subsection{Tasks \& Challenges}
\begin{enumerate}
    \item \textbf{Requirements \& Literature Review:} 
    Collect typical data requirements for scattering experiments, referencing the approaches in \cite{wang2018synchrotron, meyer2014store, moriyama2019public, godoy2021efficient} and other HPC data management projects. To further improve my knowledge within statistical analysis, I will read a few chapters of the book \textit{All of Statistics: A Concise Course in Statistical Inference}. 
    \item \textbf{Prototype Implementation:}
        \begin{itemize}
            \item Create a consistent dataset for the six approaches (using AWS S3 or AWS native services).
            \item Apply consistent chunking/partitioning logic, so each approach handles partial reads comparably.
        \end{itemize}
    \item \textbf{Testing and Metrics:}
        \begin{itemize}
            \item \emph{Dataset Volume:} Terabytes of realistic scattering data.
            \item \emph{Performance Metrics:} Read/write latency, throughput, compression ratio, and CPU overhead, storage cost (S3 usage, DynamoDB R/W units, data egress), partial-retrieval overhead.
            \item \emph{Scalability Testing:} Evaluate each approach as dataset size, concurrency, and remote append/delete/stream workloads grow.
        \end{itemize}
    \item \textbf{Analysis:}
        \begin{itemize}
            \item Compare trade-offs in cost, performance, and complexity. Provide recommendations on when each six approaches is most appropriate for large-scale facility data.
        \end{itemize}
\end{enumerate}

\subsection{Method}
The methodology framework will be a combination of \emph{experimental benchmarking} with a \emph{design–science research} segment and lastly utilizing \emph{statistical analysis}.

\subsubsection{Experimental benchmarking}
Six functionally equivalent storage backends, HDF5, Zarr, Parquet, Arrow/Feather, ROOT, and DynamoDB, will ingest the same $\sim$1 TB synchrotron/neutron dataset. Each experiment is repeated with and without the three selected compression schemes.


\subsubsection{Design–science research cycle \& Statistical analysis}
Will adopt an iterative build–evaluate–refine process: each prototype is implemented, measured against our performance and reliability targets, and then adjusted based on the results. Insights from one iteration directly inform the design of the next, ensuring continuous improvement. Will use one-way ANOVA to compare mean values of our key metrics (read/write latency, throughput, cost) across the four storage approaches. If the data violate normality or equal-variance assumptions and apply a Kruskal–Wallis test instead.



\subsection{Ethics \& Sustainability}
One of the big things is data privacy. I need to ensure that the data that will be used in the experiments is something that can be published. Regarding sustainability, I will need to discuss energy usage when utilizing cloud environments and compare it to on-premises solutions, and how it affects the carbon footprint.

\subsection{Limitations \& Risks \& Mitigations}
This thesis will only focus on AWS, meaning that no other cloud providers will be used to compare. I also don't compare with on-premises solutions using different storage solutions, such as tape. A few risk scenarios are AWS budget over usage, which can be mitigated using cost alerts and ensuring I can utilize AWS credits. Insufficient data volumes can be mitigated by using synthetic data generation as an alternative method. Another big risk is deviation from the schedule, which can be mitigated by always referring back to the plan and having meetings with both the host company and the supervisor to discuss solutions. 



\section{Evaluation \& News Value}

\subsection{Evaluation Metrics}
Will assess each storage approach using concise, single-threaded benchmarks. Read and write latency will be measured by the median and 95\% percentile. Compression efficiency combines the compression ratio with CPU time per GiB for zstd, LZ4, and gzip. Cost analysis models a one-month total cost of ownership for a 1 TB dataset in AWS hot, warm, and cold tiers. Finally, partial retrieval overhead is quantified by measuring end-to-end access times for small slices of tabular and dense array data. 

\subsection{Scientific Relevance \& Innovation / News Value}
\textbf{Scientific Facilities:} Synchrotrons, neutron sources, and other big-science labs need robust, future-proof strategies. \textbf{Data Management Community:} Expands best practices on HPC-cloud integration, partial reads, and cost-optimized big-data solutions, especially in the synchrotron/neutron community.




\section{Pre-Study}

\subsection{Literature Review Focus}
Collect typical data requirements for scattering experiments, referencing the approaches in \cite{wang2018synchrotron, meyer2014store, moriyama2019public, godoy2021efficient} and other HPC data management projects. Will survey around 30 sources, which will be grouped into five different areas: Synchrotron and neutron big‐data architectures, Cloud‐based beamline portals and remote workflows, HPC I/O libraries and object-storage formats, Cost-aware cloud storage and economics, and lastly, Benchmarking and statistical foundations.




\section{Conditions \& Schedule}

\subsection{Resources Needed and External Supervisor Involvement}
Three areas: AWS credits (which can be utilized across AWS products), Software and tools (Python, PyArrow, h5py, zarr-python, AWS SDK), Real beamline datasets (provided by Scatterin AB) + synthetic generator. \textbf{Location:} Work carried out primarily at Scatterin AB’s KTH campus office, with daily supervision opportunities.

\subsection{Timeline}
\begin{center}
    \begingroup
        \setlength{\tabcolsep}{8pt}
        \small
        \begin{tabular}{@{}lll@{}}
            \toprule
            \textbf{Task} & \textbf{Start} & \textbf{End} \\
            \midrule
            \multicolumn{3}{l}{\textbf{Pre}} \\
            Kickoff \& detailed schedule & 2025-05-05 & 2025-05-11 \\
            Literature survey \& related work & 2025-05-05 & 2025-05-25 \\
            Define thesis scope \& research questions & 2025-05-12 & 2025-05-18 \\
            Experimental plan \& metric design & 2025-05-19 & 2025-05-25 \\
            Dataset acquisition \& preparation & 2025-05-26 & 2025-06-01 \\
            Draft Introduction \& Background & 2025-05-26 & 2025-06-08 \\
            Consolidate pre-study package for supervisor & 2025-06-02 & 2025-06-08 \\
            \midrule
            \multicolumn{3}{l}{\textbf{Main}} \\
            Prototype implementation (HDF5, Zarr, Parquet, DynamoDB) & 2025-06-16 & 2025-06-29 \\
            Data ingestion \& validation & 2025-06-23 & 2025-06-29 \\
            Benchmarking framework \& Methods draft & 2025-06-30 & 2025-07-06 \\
            Self-driven experiments \& drafting (no external feedback) & 2025-07-01 & 2025-08-31 \\
            \midrule
            \multicolumn{3}{l}{\textbf{Wrap up}} \\
            Cost modelling \& TCO analysis & 2025-07-28 & 2025-08-17 \\
            Statistical analysis \& visualisation & 2025-08-04 & 2025-08-10 \\
            Draft Results \& Decision matrix & 2025-08-11 & 2025-08-17 \\
            Draft Discussion \& Conclusions & 2025-09-01 & 2025-09-07 \\
            Self-review \& internal revision & 2025-09-01 & 2025-09-07 \\
            Final formatting \& proofreading & 2025-09-08 & 2025-09-21 \\
            \bottomrule
        \end{tabular}
    \endgroup
\end{center}



\printbibliography

\end{document}
